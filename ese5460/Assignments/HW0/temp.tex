\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{geometry}
\geometry{letterpaper, margin=1in}

\title{Lagrange Multipliers: Geometric Interpretation}
\author{}
\date{}

\begin{document}

\maketitle

\section*{The Core Idea}

At an optimal point (stationary point) of a constrained optimization problem, the statement says:

$$\nabla f = \lambda_1 \nabla g_1 + \lambda_2 \nabla g_2 + \cdots + \lambda_m \nabla g_m$$

Where:
\begin{itemize}
    \item $\nabla f$ = gradient of the objective function (loss)
    \item $\nabla g_i$ = gradient of the $i$-th constraint
    \item $\lambda_i$ = Lagrange multipliers (the coefficients)
\end{itemize}

\section*{What Does This Mean?}

\subsection*{1. Geometric Interpretation}

\begin{itemize}
    \item The gradient of the loss function is \textbf{parallel to} (or lies in the span of) the constraint gradients
    \item You cannot improve the objective by moving along the constraint surface
    \item The gradient $\nabla f$ is ``blocked'' by the constraints
\end{itemize}

\subsection*{2. From Your Lecture Notes}

The notes explain this beautifully:

\begin{quote}
``At the minimum, the level curves are tangent to each other, so the normal vectors $\nabla f$ and $\nabla g$ are parallel.''
\end{quote}

And more generally:

\begin{quote}
``Why the method works: at constrained min/max, moving in any direction along the constraint surface $g = c$ should give $df/ds = 0$. So, for any $\hat{u}$ tangent to $\{g = c\}$, $\frac{df}{ds}\big|_{\hat{u}} = \nabla f \cdot \hat{u} = 0$, i.e. $\hat{u} \perp \nabla f$. Therefore $\nabla f$ is normal to tangent plane to $g = c$, and so is $\nabla g$, hence the gradient vectors are parallel.''
\end{quote}

\section*{Example from Your Notes}

For the problem: minimize $f(x,y) = x^2 + y^2$ subject to $xy = 3$

At the optimum:
\begin{itemize}
    \item $\nabla f = (2x, 2y)$
    \item $\nabla g = (y, x)$
    \item The condition becomes: $(2x, 2y) = \lambda(y, x)$
\end{itemize}

This gives:
\begin{align*}
    2x &= \lambda y \\
    2y &= \lambda x
\end{align*}

The \textbf{Lagrange multiplier $\lambda$ is the coefficient} that makes $\nabla f$ equal to a scalar multiple of $\nabla g$.

\section*{Why ``Linear Combination''?}

When you have \textbf{multiple constraints} $g_1 = c_1, g_2 = c_2, \ldots, g_m = c_m$:

$$\nabla f = \lambda_1 \nabla g_1 + \lambda_2 \nabla g_2 + \cdots + \lambda_m \nabla g_m$$

The gradient of the loss is a \textbf{weighted sum} (linear combination) of all constraint gradients, where the weights are the Lagrange multipliers.

\section*{Physical Intuition}

Think of it this way:
\begin{itemize}
    \item You want to minimize $f$, so naturally you'd move in the direction of $-\nabla f$
    \item But the constraints ``push back'' with forces proportional to $\nabla g_i$
    \item At equilibrium (the optimal point), these forces balance: $\nabla f$ equals the combined effect of all constraint forces
\end{itemize}

The Lagrange multipliers $\lambda_i$ tell you \textbf{how strongly} each constraint is ``pushing'' against your objective at the optimal point.

\end{document}
